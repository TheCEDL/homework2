{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Automatically reload changes to external code\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you will solve a classic control problem - CartPole using policy gradient methods.\n",
    "\n",
    "First, you will implement the \"vanilla\" policy gradient method, i.e., a method that repeatedly computes **unbiased** estimates $\\hat{g}$ of $\\nabla_{\\theta} E[\\sum_t r_t]$ and takes gradient ascent steps $\\theta \\rightarrow \\theta + \\epsilon \\hat{g}$ so as to increase the total rewards collected in each episode. To make sure our code can solve multiple MDPs with different policy parameterizations, provided code follows an OOP manner and represents MDP and Policy as classes.\n",
    "\n",
    "The following code constructs an instance of the MDP using OpenAI gym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym.envs.registration:Making new env: CartPole-v0\n",
      "[2016-10-12 13:50:57,388] Making new env: CartPole-v0\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from policy_gradient import util\n",
    "from policy_gradient.policy import CategoricalPolicy\n",
    "from policy_gradient.baselines.linear_feature_baseline import LinearFeatureBaseline\n",
    "from IPython.display import clear_output\n",
    "\n",
    "np.random.seed(0)\n",
    "tf.set_random_seed(0)\n",
    "\n",
    "# CartPole-v0 is a MDP with finite st ate and action space. \n",
    "# In this environment, A pendulum is attached by an un-actuated joint to a cart, \n",
    "# and the goal is to prevent it from falling over. You can apply a force of +1 or -1 to the cart.\n",
    "# A reward of +1 is provided for every timestep that the pendulum remains upright. \n",
    "# To visualize CartPole-v0, please see https://gym.openai.com/envs/CartPole-v0\n",
    "\n",
    "env = gym.make('CartPole-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: construct a neural network to represent policy\n",
    "\n",
    "Make sure you know how to construct neural network using tensorflow.\n",
    "\n",
    "1. Open **homework2/policy_gradient/policy.py**.\n",
    "2. Follow the instruction of Problem 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: compute the surrogate loss\n",
    "\n",
    "If there are $N$ episodes in an iteration, then for $i$ th episode we define $R_t^i = \\sum_{{t^′}=t}^T \\gamma^{{t^′}-t}r(s_{t^′}, a_{t^′})$ as the accumulated discounted rewards from timestep $t$ to the end of that episode, where $\\gamma$ is the discount rate.\n",
    "\n",
    "The pseudocode for the REINFORCE algorithm is as below:\n",
    "\n",
    "1. Initialize policy $\\pi$ with parameter $\\theta_1$.\n",
    "2. For iteration $k = 1, 2, ...$:\n",
    "    * Sample N episodes $\\tau_1, \\tau_2, ..., \\tau_N$ under the current policy $\\theta_k$, where $\\tau_i =(s_i^t,a_i^t,R_i^t)_{t=0}^{T−1}$. Note that the last state is dropped since no action is taken after observing the last state.\n",
    "    * Compute the empirical policy gradient using formula: $$\\hat{g} = E_{\\pi_\\theta}[\\nabla_{\\theta} log\\pi_\\theta(a_t^i | s_t^i) R_t^i]$$\n",
    "    * Take a gradient step: $\\theta_{k+1} = \\theta_k + \\epsilon \\hat{g}$.\n",
    "    \n",
    "    \n",
    "Note that we can transform the policy gradient formula as\n",
    "\n",
    "$$\\hat{g} = \\nabla_{\\theta} \\frac{1}{(NT)}(\\sum_{i=1}^N \\sum_{t=0}^T log\\pi_\\theta(a_t^i | s_t^i) R_t^i)$$\n",
    "\n",
    "and $L(\\theta) = \\frac{1}{(NT)}(\\sum_{i=1}^N \\sum_{t=0}^T log\\pi_\\theta(a_t^i | s_t^i) R_t^i)$ is called the surrogate loss. \n",
    "\n",
    "We can first construct the computation graph for $L(\\theta)$, and then take its gradient as the empirical policy gradient.\n",
    "\n",
    "\n",
    "1. Open **homework2/policy_gradient/policy.py**.\n",
    "2. Follow the instruction of Problem 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients.py:90: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "# Construct a neural network to represent policy which maps observed state to action. \n",
    "in_dim = util.flatten_space(env.observation_space)  #4\n",
    "out_dim = util.flatten_space(env.action_space)      #2\n",
    "hidden_dim = 8\n",
    "\n",
    "opt = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "policy = CategoricalPolicy(in_dim, out_dim, hidden_dim, opt, sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3\n",
    "\n",
    "Implement a function that computes the accumulated discounted rewards of each timestep _t_ from _t_ to the end of the episode.\n",
    "\n",
    "For example:\n",
    "\n",
    "```python\n",
    "rewards = [1, 1, 1]\n",
    "discount_rate = 0.99\n",
    "util.discount_cumsum(rewards, discount_rate)\n",
    "```\n",
    "\n",
    "should return:\n",
    "\n",
    "`array([ 2.9701,  1.99  ,  1.    ])`\n",
    "\n",
    "1. Open **homework/policy_gradient/util.py**.\n",
    "2. Implement the commented function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4\n",
    "\n",
    "Use baseline to reduce the variance of our gradient estimate.\n",
    "\n",
    "1. Fill in the function `process_paths` of class `PolicyOptimizer` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PolicyOptimizer(object):\n",
    "    def __init__(self, env, policy, baseline, n_iter, n_episode, path_length,\n",
    "        discount_rate=.99):\n",
    "\n",
    "        self.policy = policy\n",
    "        self.baseline = baseline\n",
    "        self.env = env\n",
    "        self.n_iter = n_iter\n",
    "        self.n_episode = n_episode\n",
    "        self.path_length = path_length\n",
    "        self.discount_rate = discount_rate\n",
    "\n",
    "    def sample_path(self):\n",
    "        obs = []\n",
    "        actions = []\n",
    "        rewards = []\n",
    "        ob = self.env.reset()\n",
    "\n",
    "        for _ in range(self.path_length):\n",
    "            a = self.policy.act(ob.reshape(1, -1)) # (1,4)\n",
    "            next_ob, r, done, _ = self.env.step(a)\n",
    "            obs.append(ob)\n",
    "            actions.append(a)\n",
    "            rewards.append(r)\n",
    "            ob = next_ob\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        return dict(\n",
    "            observations=np.array(obs),\n",
    "            actions=np.array(actions),\n",
    "            rewards=np.array(rewards),\n",
    "        )\n",
    "\n",
    "    def process_paths(self, paths):\n",
    "        for p in paths:\n",
    "            if self.baseline != None:\n",
    "                b = self.baseline.predict(p)\n",
    "            else:\n",
    "                b = 0\n",
    "            \n",
    "            # `p[\"rewards\"]` is a matrix contains the rewards of each timestep in a sample path\n",
    "            r = util.discount_cumsum(p[\"rewards\"], self.discount_rate)\n",
    "            \"\"\"\n",
    "            Problem 4:\n",
    "\n",
    "            1. Variable `b` is the reward predicted by our baseline\n",
    "            2. Use it to reduce variance and then assign the result to the variable `a`\n",
    "\n",
    "            Sample solution should be only 1 line.\n",
    "            \"\"\"\n",
    "            # YOUR CODE HERE >>>>>>\n",
    "            a = r - b\n",
    "            # <<<<<<<<\n",
    "\n",
    "            p[\"returns\"] = r\n",
    "            p[\"baselines\"] = b\n",
    "            p[\"advantages\"] = (a - a.mean()) / (a.std() + 1e-8) # normalize\n",
    "\n",
    "        obs = np.concatenate([ p[\"observations\"] for p in paths ])\n",
    "        actions = np.concatenate([ p[\"actions\"] for p in paths ])\n",
    "        rewards = np.concatenate([ p[\"rewards\"] for p in paths ])\n",
    "        advantages = np.concatenate([ p[\"advantages\"] for p in paths ])\n",
    "\n",
    "        return dict(\n",
    "            observations=obs,\n",
    "            actions=actions,\n",
    "            rewards=rewards,\n",
    "            advantages=advantages,\n",
    "        )\n",
    "\n",
    "    def train(self):\n",
    "        avg_return_list = []\n",
    "        for i in range(1, self.n_iter + 1):\n",
    "            paths = []\n",
    "            for _ in range(self.n_episode):\n",
    "                paths.append(self.sample_path())\n",
    "            data = self.process_paths(paths)\n",
    "            loss = self.policy.train(data[\"observations\"], data[\"actions\"], data[\"advantages\"])\n",
    "            avg_return = np.mean([sum(p[\"rewards\"]) for p in paths])\n",
    "            print(\"Iteration {}: Average Return = {}\".format(i, avg_return))\n",
    "            avg_return_list.append(avg_return)\n",
    "            # CartPole-v0 defines \"solving\" as getting average reward of 195.0 over 100 consecutive trials.\n",
    "            if avg_return >= 195:\n",
    "                print(\"Solve at {} iterations, which equals {} episodes.\".format(i, i*100))\n",
    "                break\n",
    "\n",
    "            if self.baseline != None:\n",
    "                self.baseline.fit(paths)\n",
    "        return avg_return_list, i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: Average Return = 18.04\n",
      "Iteration 2: Average Return = 18.83\n",
      "Iteration 3: Average Return = 21.8\n",
      "Iteration 4: Average Return = 20.61\n",
      "Iteration 5: Average Return = 23.93\n",
      "Iteration 6: Average Return = 23.09\n",
      "Iteration 7: Average Return = 27.2\n",
      "Iteration 8: Average Return = 29.16\n",
      "Iteration 9: Average Return = 31.71\n",
      "Iteration 10: Average Return = 32.73\n",
      "Iteration 11: Average Return = 34.81\n",
      "Iteration 12: Average Return = 37.38\n",
      "Iteration 13: Average Return = 39.43\n",
      "Iteration 14: Average Return = 40.16\n",
      "Iteration 15: Average Return = 41.08\n",
      "Iteration 16: Average Return = 49.69\n",
      "Iteration 17: Average Return = 50.16\n",
      "Iteration 18: Average Return = 45.54\n",
      "Iteration 19: Average Return = 49.39\n",
      "Iteration 20: Average Return = 54.45\n",
      "Iteration 21: Average Return = 48.18\n",
      "Iteration 22: Average Return = 52.51\n",
      "Iteration 23: Average Return = 49.41\n",
      "Iteration 24: Average Return = 56.92\n",
      "Iteration 25: Average Return = 55.99\n",
      "Iteration 26: Average Return = 51.51\n",
      "Iteration 27: Average Return = 62.38\n",
      "Iteration 28: Average Return = 55.51\n",
      "Iteration 29: Average Return = 58.85\n",
      "Iteration 30: Average Return = 62.69\n",
      "Iteration 31: Average Return = 57.4\n",
      "Iteration 32: Average Return = 58.77\n",
      "Iteration 33: Average Return = 65.02\n",
      "Iteration 34: Average Return = 65.5"
     ]
    }
   ],
   "source": [
    "#sess.run(tf.initialize_all_variables())\n",
    "n_iter = 200\n",
    "n_episode = 100\n",
    "path_length = 200\n",
    "discount_rate = 0.99\n",
    "baseline = LinearFeatureBaseline(env.spec)\n",
    "\n",
    "po = PolicyOptimizer(env, policy, baseline, n_iter, n_episode, path_length,\n",
    "                     discount_rate)\n",
    "\n",
    "# Train the policy optimizer\n",
    "avg_return_list = []\n",
    "iter_list = []\n",
    "for i in range(10):\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    avg_return_list_tem, iter = po.train()\n",
    "    avg_return_list.append(avg_return_list_tem)\n",
    "    iter_list.append(iter)\n",
    "    print i, 'trial =', iter\n",
    "np.savez('w_baseline', avg_return_list=avg_return_list, iter_list=iter_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation maximum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-1d9cb952c4a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mll\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mll\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mavg_return_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mavg_return_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/numpy/core/fromnumeric.pyc\u001b[0m in \u001b[0;36mamax\u001b[1;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[0;32m   2291\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2292\u001b[0m             return _methods._amax(a, axis=axis,\n\u001b[1;32m-> 2293\u001b[1;33m                                 out=out, **kwargs)\n\u001b[0m\u001b[0;32m   2294\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mamax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2295\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/numpy/core/_methods.pyc\u001b[0m in \u001b[0;36m_amax\u001b[1;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m# small reductions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_amax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mumr_maximum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_amin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
     ]
    }
   ],
   "source": [
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "ll = np.zeros([10, np.max(iter_list)])\n",
    "for i in range(10):\n",
    "    ll[i,:len(avg_return_list[i])] = avg_return_list[i]\n",
    "s = np.sum(ll, axis=0)\n",
    "nonzero = np.sum((ll != 0)+0, axis=0)\n",
    "s_ = s/nonzero\n",
    "max = np.zeros([np.max(iter_list)])\n",
    "min = np.zeros([np.max(iter_list)])\n",
    "for i in range(np.max(iter_list)):\n",
    "    max[i] = 0\n",
    "    min[i] = 1000\n",
    "    for j in range(10):\n",
    "        try:\n",
    "            if max[i] < avg_return_list[j][i]:\n",
    "                max[i] = avg_return_list[j][i]\n",
    "            if min[i] > avg_return_list[j][i]:\n",
    "                min[i] = avg_return_list[j][i]\n",
    "        except IndexError:\n",
    "            a=1\n",
    "max = max - s_\n",
    "min = s_ - min\n",
    "xs=np.linspace(1,np.max(iter_list),np.max(iter_list))\n",
    "plt.errorbar(xs, s_, yerr = [min, max])\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Avg_return')\n",
    "#plt.show()\n",
    "plt.savefig('without_variance_reduce_max.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103,)\n"
     ]
    }
   ],
   "source": [
    "print min.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-80-d92260406ffa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mxs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mavg_return_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mavg_return_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mavg_return_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Iteration'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Avg_return'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/matplotlib/pyplot.pyc\u001b[0m in \u001b[0;36mplot\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   3152\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3153\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3154\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3155\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3156\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwashold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/matplotlib/__init__.pyc\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1809\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[0;32m   1810\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[1;32m-> 1811\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1812\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1813\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/matplotlib/axes/_axes.pyc\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1427\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1428\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1429\u001b[0m             \u001b[0mlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/matplotlib/axes/_base.pyc\u001b[0m in \u001b[0;36madd_line\u001b[1;34m(self, line)\u001b[0m\n\u001b[0;32m   1697\u001b[0m             \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_clip_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1699\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_line_limits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1700\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1701\u001b[0m             \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_line%d'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/matplotlib/axes/_base.pyc\u001b[0m in \u001b[0;36m_update_line_limits\u001b[1;34m(self, line)\u001b[0m\n\u001b[0;32m   1708\u001b[0m         \u001b[0mFigures\u001b[0m \u001b[0mout\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mlimit\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdating\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataLim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1709\u001b[0m         \"\"\"\n\u001b[1;32m-> 1710\u001b[1;33m         \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1711\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvertices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1712\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/matplotlib/lines.pyc\u001b[0m in \u001b[0;36mget_path\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    924\u001b[0m         \"\"\"\n\u001b[0;32m    925\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_invalidy\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_invalidx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 926\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    927\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/matplotlib/lines.pyc\u001b[0m in \u001b[0;36mrecache\u001b[1;34m(self, always)\u001b[0m\n\u001b[0;32m    618\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myconv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 620\u001b[1;33m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myconv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    621\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/numpy/core/numeric.pyc\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \"\"\"\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "xs=np.linspace(1,len(avg_return_list),len(avg_return_list))\n",
    "plt.plot(xs, avg_return_list)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Avg_return')\n",
    "plt.show()\n",
    "plt.savefig('with_variance_reduce.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xs=np.linspace(1,len(avg_return_list_n),len(avg_return_list_n))\n",
    "plt.plot(xs, avg_return_list_n)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Avg_return')\n",
    "plt.show()\n",
    "plt.savefig('without_variance_reduce.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xs=np.linspace(1,len(avg_return_list),len(avg_return_list))\n",
    "xs_n=np.linspace(1,len(avg_return_list_n),len(avg_return_list_n))\n",
    "plt.plot(xs, avg_return_list, xs_n, avg_return_list_n)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Avg_return')\n",
    "plt.legend(['With variance reduction', 'Without variance reduction'], loc='upper left')\n",
    "plt.savefig('compare.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify your solutions\n",
    "\n",
    "if you solve the problems 1~4 correctly, your will solve CartPole with roughly ~ 80 iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 5\n",
    "Replacing line \n",
    "\n",
    "`baseline = LinearFeatureBaseline(env.spec)` \n",
    "\n",
    "with \n",
    "\n",
    "`baseline = None`\n",
    "\n",
    "can remove the baseline.\n",
    "\n",
    "Modify the code to compare the variance and performance before and after adding baseline.\n",
    "Then, write a report about your findings. (with figures is better)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 6\n",
    "\n",
    "In function process_paths of class `PolicyOptimizer`, why we need to normalize the advantages? i.e., what's the usage of this line:\n",
    "\n",
    "`p[\"advantages\"] = (a - a.mean()) / (a.std() + 1e-8)`\n",
    "\n",
    "Include the answer in your report."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
